{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nimport string\nfrom string import digits\nimport matplotlib.pyplot as plt\nimport re\n\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import LSTM, Input, Dense,Embedding, Concatenate, TimeDistributed\nfrom keras.models import Model\nfrom tensorflow.keras.utils import plot_model\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint","execution_count":242,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"lines=pd.read_csv(\"../input/test-2/eng-asm.csv\",encoding='utf-8')","execution_count":243,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.isna().any()","execution_count":244,"outputs":[{"output_type":"execute_result","execution_count":244,"data":{"text/plain":"english_sentence     False\nassamese_sentence    False\ndtype: bool"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.drop_duplicates(inplace=True)","execution_count":245,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.head()","execution_count":246,"outputs":[{"output_type":"execute_result","execution_count":246,"data":{"text/plain":"  english_sentence assamese_sentence\n0  Hi.              নমস্কাৰ।        \n1  Hi.              হাই।            \n2  Run!             দৌৰ!            \n3  Run!             দৌৰাঁ!          \n4  Run!             দৌৰক!           ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>assamese_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>নমস্কাৰ।</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hi.</td>\n      <td>হাই।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>দৌৰ!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Run!</td>\n      <td>দৌৰাঁ!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Run!</td>\n      <td>দৌৰক!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lowercase all characters\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\nlines['assamese_sentence']=lines['assamese_sentence'].apply(lambda x: x.lower())\n\n# Remove quotes\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n\n# Remove all the special characters\nexclude = set(string.punctuation)\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n\n# Remove all numbers from text\n    #Remove english numbers\nremove_digits = str.maketrans('', '', digits)\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\nlines['assamese_sentence']=lines['assamese_sentence'].apply(lambda x: x.translate(remove_digits))\n    # Remove assamese numbers\nlines['assamese_sentence'] = lines['assamese_sentence'].apply(lambda x: re.sub(\"[০১২৩৪৫৬৭৮৯]\", \"\", x))\n\n# Remove white spaces\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\nlines['assamese_sentence']=lines['assamese_sentence'].apply(lambda x: x.strip())\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\nlines['assamese_sentence']=lines['assamese_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n\n# Add start and end tokens to target sequences\nlines['assamese_sentence'] = lines['assamese_sentence'].apply(lambda x : 'START_ '+ x + ' _END')\n\n# Get lengths\nlines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\nlines['length_assm_sentence']=lines['assamese_sentence'].apply(lambda x:len(x.split(\" \")))","execution_count":247,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.head()","execution_count":248,"outputs":[{"output_type":"execute_result","execution_count":248,"data":{"text/plain":"  english_sentence     assamese_sentence  length_eng_sentence  length_assm_sentence\n0  hi               START_ নমস্কাৰ। _END  1                    3                   \n1  hi               START_ হাই। _END      1                    3                   \n2  run              START_ দৌৰ! _END      1                    3                   \n3  run              START_ দৌৰাঁ! _END    1                    3                   \n4  run              START_ দৌৰক! _END     1                    3                   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>assamese_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_assm_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hi</td>\n      <td>START_ নমস্কাৰ। _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hi</td>\n      <td>START_ হাই। _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>run</td>\n      <td>START_ দৌৰ! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>run</td>\n      <td>START_ দৌৰাঁ! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>run</td>\n      <td>START_ দৌৰক! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get English and Assamese Vocabulary\nall_eng_words=set()\nfor eng in lines['english_sentence']:\n    for word in eng.split():\n        if word not in all_eng_words:\n            all_eng_words.add(word)\n\nall_assamese_words=set()\nfor assm in lines['assamese_sentence']:\n    for word in assm.split():\n        if word not in all_assamese_words:\n            all_assamese_words.add(word)","execution_count":249,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Vocab size of english words:',len(all_eng_words))\nprint('Vocab size of assamese words:',len(all_assamese_words))","execution_count":250,"outputs":[{"output_type":"stream","text":"Vocab size of english words: 1218\nVocab size of assamese words: 2192\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length_src=max(lines['length_eng_sentence'])\nmax_length_tar=max(lines['length_assm_sentence'])\nprint(\"maximum length of English Sentence:\",max_length_src)\nprint(\"maximum length of Assamese Sentence:\",max_length_tar)","execution_count":251,"outputs":[{"output_type":"stream","text":"maximum length of English Sentence: 15\nmaximum length of Assamese Sentence: 16\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.head()","execution_count":252,"outputs":[{"output_type":"execute_result","execution_count":252,"data":{"text/plain":"  english_sentence     assamese_sentence  length_eng_sentence  length_assm_sentence\n0  hi               START_ নমস্কাৰ। _END  1                    3                   \n1  hi               START_ হাই। _END      1                    3                   \n2  run              START_ দৌৰ! _END      1                    3                   \n3  run              START_ দৌৰাঁ! _END    1                    3                   \n4  run              START_ দৌৰক! _END     1                    3                   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>assamese_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_assm_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hi</td>\n      <td>START_ নমস্কাৰ। _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hi</td>\n      <td>START_ হাই। _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>run</td>\n      <td>START_ দৌৰ! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>run</td>\n      <td>START_ দৌৰাঁ! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>run</td>\n      <td>START_ দৌৰক! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.shape","execution_count":253,"outputs":[{"output_type":"execute_result","execution_count":253,"data":{"text/plain":"(1745, 4)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"maximum length of Assamese Sentence \",max(lines['length_assm_sentence']))\nprint(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))","execution_count":254,"outputs":[{"output_type":"stream","text":"maximum length of Assamese Sentence  16\nmaximum length of English Sentence  15\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length_src=max(lines['length_assm_sentence'])\nmax_length_tar=max(lines['length_eng_sentence'])","execution_count":255,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_words = sorted(list(all_eng_words))\ntarget_words = sorted(list(all_assamese_words))\nnum_encoder_tokens = len(all_eng_words)\nnum_decoder_tokens = len(all_assamese_words)\nnum_encoder_tokens, num_decoder_tokens","execution_count":256,"outputs":[{"output_type":"execute_result","execution_count":256,"data":{"text/plain":"(1218, 2192)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_decoder_tokens += 1 #for zero padding\n","execution_count":257,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\ntarget_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])","execution_count":258,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\nreverse_target_char_index = dict((i, word) for word, i in target_token_index.items())","execution_count":259,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=0\nfor k,v in reverse_input_char_index.items():\n    print(k,'->',v)\n    c+=1\n    if c==10:\n        break","execution_count":260,"outputs":[{"output_type":"stream","text":"1 -> a\n2 -> aah\n3 -> able\n4 -> aboard\n5 -> about\n6 -> above\n7 -> abroad\n8 -> absent\n9 -> accept\n10 -> accepted\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=0\nfor k,v in input_token_index.items():\n    print(k,'->',v)\n    c+=1\n    if c==10:\n        break","execution_count":261,"outputs":[{"output_type":"stream","text":"a -> 1\naah -> 2\nable -> 3\naboard -> 4\nabout -> 5\nabove -> 6\nabroad -> 7\nabsent -> 8\naccept -> 9\naccepted -> 10\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines = shuffle(lines)\nlines.head()","execution_count":262,"outputs":[{"output_type":"execute_result","execution_count":262,"data":{"text/plain":"                          english_sentence                          assamese_sentence  length_eng_sentence  length_assm_sentence\n418   you cant scare me                     START_ তুমি মোক ভয় দেখুৱাব নোৱাৰা। _END   4                    7                   \n967   how are we feeling today              START_ আজি আপুনি কেনে অনুভৱ কৰি আছে? _END  5                    8                   \n886   he will be back shortly               START_ তেওঁ সোনকালে উভতি আহিব। _END        5                    6                   \n135   were freaks                           START_ আমি অদ্ভুত। _END                    2                    4                   \n1608  i heard something fall to the ground  START_ মই মাটিত কিবা পৰা শুনিছোঁ। _END     7                    7                   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>assamese_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_assm_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>418</th>\n      <td>you cant scare me</td>\n      <td>START_ তুমি মোক ভয় দেখুৱাব নোৱাৰা। _END</td>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>967</th>\n      <td>how are we feeling today</td>\n      <td>START_ আজি আপুনি কেনে অনুভৱ কৰি আছে? _END</td>\n      <td>5</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>he will be back shortly</td>\n      <td>START_ তেওঁ সোনকালে উভতি আহিব। _END</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>were freaks</td>\n      <td>START_ আমি অদ্ভুত। _END</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1608</th>\n      <td>i heard something fall to the ground</td>\n      <td>START_ মই মাটিত কিবা পৰা শুনিছোঁ। _END</td>\n      <td>7</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = lines['english_sentence'], lines['assamese_sentence']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\nX_train.shape, X_test.shape","execution_count":263,"outputs":[{"output_type":"execute_result","execution_count":263,"data":{"text/plain":"((1396,), (349,))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_batch(X = X_train, y = y_train, batch_size = 128):\n    ''' Generate a batch of data '''\n    while True:\n        for j in range(0, len(X), batch_size):\n            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n                for t, word in enumerate(input_text.split()):\n                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n                for t, word in enumerate(target_text.split()):\n                    if t<len(target_text.split())-1:\n                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n                    if t>0:\n                        # decoder target sequence (one hot encoded)\n                        # does not include the START_ token\n                        # Offset by one timestep\n                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n            yield([encoder_input_data, decoder_input_data], decoder_target_data)","execution_count":264,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_dim=256","execution_count":265,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoder\nencoder_inputs = Input(shape=(None,))\nenc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]","execution_count":266,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\ndec_emb = dec_emb_layer(decoder_inputs)\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don't use the\n# return states in the training model, but we will use them in inference.\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb,\n                                     initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)","execution_count":267,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy')","execution_count":268,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":269,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_11 (InputLayer)           (None, None)         0                                            \n__________________________________________________________________________________________________\ninput_12 (InputLayer)           (None, None)         0                                            \n__________________________________________________________________________________________________\nembedding_11 (Embedding)        (None, None, 256)    311808      input_11[0][0]                   \n__________________________________________________________________________________________________\nembedding_12 (Embedding)        (None, None, 256)    561408      input_12[0][0]                   \n__________________________________________________________________________________________________\nlstm_11 (LSTM)                  [(None, 256), (None, 525312      embedding_11[0][0]               \n__________________________________________________________________________________________________\nlstm_12 (LSTM)                  [(None, None, 256),  525312      embedding_12[0][0]               \n                                                                 lstm_11[0][1]                    \n                                                                 lstm_11[0][2]                    \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, None, 2193)   563601      lstm_12[0][0]                    \n==================================================================================================\nTotal params: 2,487,441\nTrainable params: 2,487,441\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_samples = len(X_train)\nval_samples = len(X_test)\nbatch_size = 128\nepochs = 100","execution_count":270,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n                    steps_per_epoch = train_samples//batch_size,\n                    epochs=epochs,\n                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n                    validation_steps = val_samples//batch_size)\n\n","execution_count":271,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n10/10 [==============================] - 4s 362ms/step - loss: 6.8769 - val_loss: 6.0654\nEpoch 2/100\n10/10 [==============================] - 1s 66ms/step - loss: 5.7784 - val_loss: 5.9746\nEpoch 3/100\n10/10 [==============================] - 1s 62ms/step - loss: 5.5337 - val_loss: 5.8298\nEpoch 4/100\n10/10 [==============================] - 1s 66ms/step - loss: 5.3949 - val_loss: 5.8783\nEpoch 5/100\n10/10 [==============================] - 1s 64ms/step - loss: 5.2854 - val_loss: 5.8329\nEpoch 6/100\n10/10 [==============================] - 1s 64ms/step - loss: 5.1945 - val_loss: 5.7552\nEpoch 7/100\n10/10 [==============================] - 1s 62ms/step - loss: 5.0926 - val_loss: 5.7835\nEpoch 8/100\n10/10 [==============================] - 1s 60ms/step - loss: 4.9747 - val_loss: 5.7457\nEpoch 9/100\n10/10 [==============================] - 1s 89ms/step - loss: 4.8811 - val_loss: 5.6853\nEpoch 10/100\n10/10 [==============================] - 1s 61ms/step - loss: 4.7864 - val_loss: 5.7292\nEpoch 11/100\n10/10 [==============================] - 1s 60ms/step - loss: 4.6815 - val_loss: 5.7353\nEpoch 12/100\n10/10 [==============================] - 1s 60ms/step - loss: 4.5884 - val_loss: 5.7138\nEpoch 13/100\n10/10 [==============================] - 1s 61ms/step - loss: 4.5113 - val_loss: 5.6605\nEpoch 14/100\n10/10 [==============================] - 1s 60ms/step - loss: 4.3951 - val_loss: 5.6683\nEpoch 15/100\n10/10 [==============================] - 1s 60ms/step - loss: 4.2961 - val_loss: 5.5918\nEpoch 16/100\n10/10 [==============================] - 1s 62ms/step - loss: 4.2084 - val_loss: 5.6966\nEpoch 17/100\n10/10 [==============================] - 1s 62ms/step - loss: 4.1127 - val_loss: 5.6784\nEpoch 18/100\n10/10 [==============================] - 1s 60ms/step - loss: 4.0131 - val_loss: 5.5336\nEpoch 19/100\n10/10 [==============================] - 1s 61ms/step - loss: 3.8946 - val_loss: 5.6656\nEpoch 20/100\n10/10 [==============================] - 1s 62ms/step - loss: 3.8022 - val_loss: 5.6369\nEpoch 21/100\n10/10 [==============================] - 1s 61ms/step - loss: 3.7292 - val_loss: 5.4879\nEpoch 22/100\n10/10 [==============================] - 1s 60ms/step - loss: 3.6272 - val_loss: 5.6726\nEpoch 23/100\n10/10 [==============================] - 1s 61ms/step - loss: 3.5354 - val_loss: 5.5792\nEpoch 24/100\n10/10 [==============================] - 1s 62ms/step - loss: 3.4458 - val_loss: 5.4425\nEpoch 25/100\n10/10 [==============================] - 1s 59ms/step - loss: 3.3576 - val_loss: 5.6011\nEpoch 26/100\n10/10 [==============================] - 1s 81ms/step - loss: 3.2604 - val_loss: 5.5605\nEpoch 27/100\n10/10 [==============================] - 1s 74ms/step - loss: 3.1942 - val_loss: 5.4134\nEpoch 28/100\n10/10 [==============================] - 1s 59ms/step - loss: 3.1089 - val_loss: 5.5875\nEpoch 29/100\n10/10 [==============================] - 1s 61ms/step - loss: 3.0108 - val_loss: 5.5394\nEpoch 30/100\n10/10 [==============================] - 1s 80ms/step - loss: 2.9267 - val_loss: 5.4014\nEpoch 31/100\n10/10 [==============================] - 1s 91ms/step - loss: 2.8738 - val_loss: 5.5886\nEpoch 32/100\n10/10 [==============================] - 1s 64ms/step - loss: 2.7799 - val_loss: 5.5466\nEpoch 33/100\n10/10 [==============================] - 1s 66ms/step - loss: 2.7161 - val_loss: 5.3666\nEpoch 34/100\n10/10 [==============================] - 1s 69ms/step - loss: 2.6405 - val_loss: 5.5297\nEpoch 35/100\n10/10 [==============================] - 1s 64ms/step - loss: 2.5648 - val_loss: 5.4889\nEpoch 36/100\n10/10 [==============================] - 1s 65ms/step - loss: 2.4865 - val_loss: 5.3251\nEpoch 37/100\n10/10 [==============================] - 1s 65ms/step - loss: 2.4124 - val_loss: 5.5091\nEpoch 38/100\n10/10 [==============================] - 1s 64ms/step - loss: 2.3508 - val_loss: 5.4670\nEpoch 39/100\n10/10 [==============================] - 1s 64ms/step - loss: 2.2794 - val_loss: 5.2911\nEpoch 40/100\n10/10 [==============================] - 1s 63ms/step - loss: 2.2007 - val_loss: 5.5195\nEpoch 41/100\n10/10 [==============================] - 1s 63ms/step - loss: 2.1393 - val_loss: 5.4559\nEpoch 42/100\n10/10 [==============================] - 1s 74ms/step - loss: 2.0891 - val_loss: 5.2784\nEpoch 43/100\n10/10 [==============================] - 1s 72ms/step - loss: 2.0177 - val_loss: 5.4982\nEpoch 44/100\n10/10 [==============================] - 1s 60ms/step - loss: 1.9717 - val_loss: 5.4291\nEpoch 45/100\n10/10 [==============================] - 1s 61ms/step - loss: 1.9019 - val_loss: 5.2266\nEpoch 46/100\n10/10 [==============================] - 1s 60ms/step - loss: 1.8351 - val_loss: 5.4408\nEpoch 47/100\n10/10 [==============================] - 1s 63ms/step - loss: 1.7850 - val_loss: 5.3760\nEpoch 48/100\n10/10 [==============================] - 1s 62ms/step - loss: 1.7231 - val_loss: 5.1968\nEpoch 49/100\n10/10 [==============================] - 1s 66ms/step - loss: 1.6619 - val_loss: 5.4346\nEpoch 50/100\n10/10 [==============================] - 1s 67ms/step - loss: 1.6164 - val_loss: 5.3575\nEpoch 51/100\n10/10 [==============================] - 1s 69ms/step - loss: 1.5548 - val_loss: 5.1742\nEpoch 52/100\n10/10 [==============================] - 1s 62ms/step - loss: 1.5013 - val_loss: 5.4304\nEpoch 53/100\n10/10 [==============================] - 1s 62ms/step - loss: 1.4618 - val_loss: 5.3571\nEpoch 54/100\n10/10 [==============================] - 1s 61ms/step - loss: 1.4170 - val_loss: 5.1485\nEpoch 55/100\n10/10 [==============================] - 1s 61ms/step - loss: 1.3606 - val_loss: 5.4019\nEpoch 56/100\n10/10 [==============================] - 1s 60ms/step - loss: 1.3106 - val_loss: 5.3110\nEpoch 57/100\n10/10 [==============================] - 1s 61ms/step - loss: 1.2686 - val_loss: 5.0985\nEpoch 58/100\n10/10 [==============================] - 1s 60ms/step - loss: 1.2293 - val_loss: 5.3758\nEpoch 59/100\n10/10 [==============================] - 1s 63ms/step - loss: 1.1714 - val_loss: 5.3000\nEpoch 60/100\n10/10 [==============================] - 1s 85ms/step - loss: 1.1332 - val_loss: 5.0929\nEpoch 61/100\n10/10 [==============================] - 1s 61ms/step - loss: 1.0925 - val_loss: 5.3698\nEpoch 62/100\n10/10 [==============================] - 1s 60ms/step - loss: 1.0462 - val_loss: 5.3130\nEpoch 63/100\n10/10 [==============================] - 1s 62ms/step - loss: 1.0140 - val_loss: 5.0790\nEpoch 64/100\n10/10 [==============================] - 1s 63ms/step - loss: 0.9764 - val_loss: 5.3707\nEpoch 65/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.9436 - val_loss: 5.2775\nEpoch 66/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.9034 - val_loss: 5.0635\nEpoch 67/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.8685 - val_loss: 5.3405\nEpoch 68/100\n10/10 [==============================] - 1s 61ms/step - loss: 0.8373 - val_loss: 5.2331\nEpoch 69/100\n10/10 [==============================] - 1s 61ms/step - loss: 0.8044 - val_loss: 5.0268\nEpoch 70/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.7663 - val_loss: 5.3470\nEpoch 71/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.7391 - val_loss: 5.2515\nEpoch 72/100\n10/10 [==============================] - 1s 61ms/step - loss: 0.7077 - val_loss: 5.0250\nEpoch 73/100\n10/10 [==============================] - 1s 63ms/step - loss: 0.6769 - val_loss: 5.3501\nEpoch 74/100\n10/10 [==============================] - 1s 61ms/step - loss: 0.6583 - val_loss: 5.2484\nEpoch 75/100\n10/10 [==============================] - 1s 61ms/step - loss: 0.6237 - val_loss: 5.0174\nEpoch 76/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.6032 - val_loss: 5.3551\nEpoch 77/100\n10/10 [==============================] - 1s 88ms/step - loss: 0.5857 - val_loss: 5.2324\nEpoch 78/100\n10/10 [==============================] - 1s 65ms/step - loss: 0.5639 - val_loss: 5.0050\nEpoch 79/100\n10/10 [==============================] - 1s 87ms/step - loss: 0.5336 - val_loss: 5.3152\nEpoch 80/100\n10/10 [==============================] - 1s 80ms/step - loss: 0.5100 - val_loss: 5.2086\nEpoch 81/100\n10/10 [==============================] - 1s 63ms/step - loss: 0.4941 - val_loss: 5.0137\nEpoch 82/100\n","name":"stdout"},{"output_type":"stream","text":"10/10 [==============================] - 1s 64ms/step - loss: 0.4681 - val_loss: 5.3396\nEpoch 83/100\n10/10 [==============================] - 1s 61ms/step - loss: 0.4531 - val_loss: 5.2303\nEpoch 84/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.4329 - val_loss: 5.0232\nEpoch 85/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.4230 - val_loss: 5.3560\nEpoch 86/100\n10/10 [==============================] - 1s 61ms/step - loss: 0.4018 - val_loss: 5.2258\nEpoch 87/100\n10/10 [==============================] - 1s 61ms/step - loss: 0.3879 - val_loss: 5.0044\nEpoch 88/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.3718 - val_loss: 5.3481\nEpoch 89/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.3592 - val_loss: 5.2316\nEpoch 90/100\n10/10 [==============================] - 1s 64ms/step - loss: 0.3502 - val_loss: 5.0074\nEpoch 91/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.3302 - val_loss: 5.3426\nEpoch 92/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.3178 - val_loss: 5.2378\nEpoch 93/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.3037 - val_loss: 5.0253\nEpoch 94/100\n10/10 [==============================] - 1s 90ms/step - loss: 0.2979 - val_loss: 5.3922\nEpoch 95/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.2851 - val_loss: 5.2788\nEpoch 96/100\n10/10 [==============================] - 1s 65ms/step - loss: 0.2754 - val_loss: 5.0458\nEpoch 97/100\n10/10 [==============================] - 1s 61ms/step - loss: 0.2672 - val_loss: 5.4046\nEpoch 98/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.2576 - val_loss: 5.2681\nEpoch 99/100\n10/10 [==============================] - 1s 63ms/step - loss: 0.2468 - val_loss: 5.0547\nEpoch 100/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.2469 - val_loss: 5.4106\n","name":"stdout"},{"output_type":"execute_result","execution_count":271,"data":{"text/plain":"<keras.callbacks.History at 0x7f5d37c77a20>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode the input sequence to get the \"thought vectors\"\nencoder_model = Model(encoder_inputs, encoder_states)\n\n# Decoder setup\n# Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\ndec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n\n# To predict the next word in the sequence, set the initial states to the states from the previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2)\n","execution_count":272,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0] = target_token_index['START_']\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += ' '+sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        if (sampled_char == '_END' or\n           len(decoded_sentence) > 50):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence","execution_count":273,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = generate_batch(X_train, y_train, batch_size = 1)\nfor k in range(-1,20):\n    k+=1\n    (input_seq, actual_output), _ = next(train_gen)\n    decoded_sentence = decode_sequence(input_seq)\n    print('Input English sentence:', X_train[k:k+1].values[0])\n    print('Actual Assamese Translation:', y_train[k:k+1].values[0][6:-4])\n    print('Predicted Assamese Translation:', decoded_sentence[:-4])\n    print('*************************\\n')","execution_count":275,"outputs":[{"output_type":"stream","text":"Input English sentence: youre to do as i tell you\nActual Assamese Translation:  মই কোৱামতে আপুনি কৰিব লাগিব। \nPredicted Assamese Translation:  মই কোৱামতে তুমি কৰিব লাগিব। \n*************************\n\nInput English sentence: whats toms girlfriends name\nActual Assamese Translation:  টমৰ গাৰ্লফ্ৰেণ্ডৰ নাম কি? \nPredicted Assamese Translation:  টমৰ গাৰ্লফ্ৰেণ্ডৰ নাম কি? \n*************************\n\nInput English sentence: tom shot a kid in the back\nActual Assamese Translation:  টমে সৰু ল'ৰা এটাৰ পিঠিত গুলি মাৰিলে। \nPredicted Assamese Translation:  টমে সৰু ল'ৰা এটাৰ পিঠিত গুলি মাৰিলে। \n*************************\n\nInput English sentence: were baking cookies\nActual Assamese Translation:  আমি কুকিজ বেক কৰি আছোঁ। \nPredicted Assamese Translation:  আমি কুকিজ বেক কৰি আছোঁ। \n*************************\n\nInput English sentence: you took the wrong key\nActual Assamese Translation:  তুমি ভুল চাবি লৈছা। \nPredicted Assamese Translation:  তুমি ভুল চাবি লৈছে। \n*************************\n\nInput English sentence: how high can you jump\nActual Assamese Translation:  আপুনি কিমান ওখ জঁপিয়াব পাৰে? \nPredicted Assamese Translation:  তুমি কিমান ওখ জঁপিয়াব পাৰা? \n*************************\n\nInput English sentence: they called for an end to the fighting\nActual Assamese Translation:  সিহঁতে কাজিয়াটো শেষ হোৱা বিচাৰিছে। \nPredicted Assamese Translation:  সিহঁতে কাজিয়াটো শেষ হোৱা বিচাৰিছে। \n*************************\n\nInput English sentence: run\nActual Assamese Translation:  দৌৰ! \nPredicted Assamese Translation:  দৌৰক! \n*************************\n\nInput English sentence: he lives in comfort\nActual Assamese Translation:  সি আৰামত থাকে। \nPredicted Assamese Translation:  তেওঁ আৰামত থাকে। \n*************************\n\nInput English sentence: my father likes tennis\nActual Assamese Translation:  মোৰ দেউতাই টেনিছ ভাল পায়। \nPredicted Assamese Translation:  মোৰ দেউতাই টেনিছ ভাল পায়। \n*************************\n\nInput English sentence: you dont believe it do you\nActual Assamese Translation:  আপুনি বিশ্বাস নকৰে, নহয় জানো? \nPredicted Assamese Translation:  তুমি বিশ্বাস নকৰা, কৰা জানো? \n*************************\n\nInput English sentence: tom wasnt in the car\nActual Assamese Translation:  টম্‌ গাড়ীত নাছিল। \nPredicted Assamese Translation:  টম্‌ গাড়ীত নাছিল। \n*************************\n\nInput English sentence: whats going on here\nActual Assamese Translation:  ইয়াত কি চলি আছে? \nPredicted Assamese Translation:  ইয়াত কি চলি আছে? \n*************************\n\nInput English sentence: did you watch the game\nActual Assamese Translation:  আপুনি খেলখন চাইছেনে? \nPredicted Assamese Translation:  আপুনি খেলখন চাইছেনে? \n*************************\n\nInput English sentence: would you like something to drink\nActual Assamese Translation:  কিবা খাবা নেকি? \nPredicted Assamese Translation:  কিবা খাব নেকি? \n*************************\n\nInput English sentence: have you read this book yet\nActual Assamese Translation:  তুমি এই কিতাপখন পঢ়িছানে বাৰু? \nPredicted Assamese Translation:  তুমি এই কিতাপখন পঢ়িলানে? \n*************************\n\nInput English sentence: im waiting for my mother\nActual Assamese Translation:  মই মোৰ মাৰ বাবে ৰৈ আছোঁ। \nPredicted Assamese Translation:  মই মোৰ মাৰ বাবে ৰৈ আছোঁ। \n*************************\n\nInput English sentence: our money ran out\nActual Assamese Translation:  আমাৰ পইচা শেষ গৈ গ'ল। \nPredicted Assamese Translation:  আমাৰ টকা শেষ হৈ গ'ল। \n*************************\n\nInput English sentence: this mango is sweet\nActual Assamese Translation:  এই আমটো মিঠা। \nPredicted Assamese Translation:  এই আমটো মিঠা। \n*************************\n\nInput English sentence: now and then she plays tennis\nActual Assamese Translation:  এতিয়া আৰু তেতিয়া তেওঁ টেনিছ খেলে। \nPredicted Assamese Translation:  এতিয়া আৰু তেতিয়া তাই টেনিছ খেলে। \n*************************\n\nInput English sentence: how long have you had this problem\nActual Assamese Translation:  আপোনাৰ এই সমস্যাটো কিমান দিন ধৰি হৈ আছে? \nPredicted Assamese Translation:  আপোনাৰ এই বিষ কিমান দিন ধৰি হৈ আছে? \n*************************\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen = generate_batch(X_test, y_test, batch_size = 1)\nfor k in range(-1,20):\n    k+=1\n    (input_seq, actual_output), _ = next(test_gen)\n    decoded_sentence = decode_sequence(input_seq)\n    print('Input English sentence:', X_test[k:k+1].values[0])\n    print('Actual Assamese Translation:', y_test[k:k+1].values[0][6:-4])\n    print('Predicted Assamese Translation:', decoded_sentence[:-4])\n    print('*************************\\n')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}