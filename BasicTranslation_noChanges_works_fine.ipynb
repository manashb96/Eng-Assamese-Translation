{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport string\nfrom string import digits\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\n\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input, LSTM, Embedding, Dense\nfrom keras.models import Model\n\nprint(os.listdir(\"../input\"))\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\npd.set_option('display.max_colwidth', -1)\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"['hindienglish-corpora', 'test-2']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"lines=pd.read_csv(\"../input/test-2/eng-asm.csv\",encoding='utf-8')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.head(20)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   english_sentence assamese_sentence\n0   Hi.              নমস্কাৰ।        \n1   Hi.              হাই।            \n2   Run!             দৌৰ!            \n3   Run!             দৌৰাঁ!          \n4   Run!             দৌৰক!           \n5   Who?             কোন?            \n6   Wow!             বাঃ!            \n7   Fire!            জুই!            \n8   Help!            সহায় কৰাঁ!     \n9   Help!            সহায় কৰক!      \n10  Jump.            জঁপিয়াওক।      \n11  Stop!            ৰ'ব!            \n12  Wait!            ৰ'ব!            \n13  Wait!            ৰ'বা!           \n14  Hello!           নমস্কাৰ!        \n15  Hello!           হেৰা!           \n16  Hurry!           লৰালৰিকৈ!       \n17  Hurry!           সোনকালে!        \n18  Hurry!           খৰধৰকৈ!         \n19  Relax.           শান্ত হোৱা।     ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>assamese_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>নমস্কাৰ।</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hi.</td>\n      <td>হাই।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>দৌৰ!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Run!</td>\n      <td>দৌৰাঁ!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Run!</td>\n      <td>দৌৰক!</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Who?</td>\n      <td>কোন?</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Wow!</td>\n      <td>বাঃ!</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Fire!</td>\n      <td>জুই!</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Help!</td>\n      <td>সহায় কৰাঁ!</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Help!</td>\n      <td>সহায় কৰক!</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Jump.</td>\n      <td>জঁপিয়াওক।</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Stop!</td>\n      <td>ৰ'ব!</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Wait!</td>\n      <td>ৰ'ব!</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Wait!</td>\n      <td>ৰ'বা!</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Hello!</td>\n      <td>নমস্কাৰ!</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Hello!</td>\n      <td>হেৰা!</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Hurry!</td>\n      <td>লৰালৰিকৈ!</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Hurry!</td>\n      <td>সোনকালে!</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Hurry!</td>\n      <td>খৰধৰকৈ!</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Relax.</td>\n      <td>শান্ত হোৱা।</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isnull(lines).sum()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"english_sentence     0\nassamese_sentence    0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.drop_duplicates(inplace=True)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### Let us pick any 25000 rows from the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lowercase all characters\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\nlines['assamese_sentence']=lines['assamese_sentence'].apply(lambda x: x.lower())","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.shape","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(1745, 2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove quotes\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n#lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exclude = set(string.punctuation)\nprint(exclude)","execution_count":9,"outputs":[{"output_type":"stream","text":"{'`', '/', '&', '~', '}', '_', ';', '?', '<', '|', ':', '^', '#', \"'\", '[', '=', '(', '{', '-', '!', '\\\\', '+', '$', '\"', '*', ',', '>', '%', '@', ']', '.', ')'}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"exclude = set(string.punctuation) # Set of all special characters\n# Remove all the special characters\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n#lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove all numbers from text\nremove_digits = str.maketrans('', '', digits)\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\nlines['assamese_sentence']=lines['assamese_sentence'].apply(lambda x: x.translate(remove_digits))\n\nlines['assamese_sentence'] = lines['assamese_sentence'].apply(lambda x: re.sub(\"[০১২৩৪৫৬৭৮৯]\", \"\", x))\n\n# Remove extra spaces\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\nlines['assamese_sentence']=lines['assamese_sentence'].apply(lambda x: x.strip())\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\nlines['assamese_sentence']=lines['assamese_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add start and end tokens to target sequences\nlines['assamese_sentence'] = lines['assamese_sentence'].apply(lambda x : 'START_ '+ x + ' _END')","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.tail()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"                                                        english_sentence                                                                      assamese_sentence\n1740  its so hot that you could cook an egg on the hood of a car          START_ ইমানেই গৰম যে আপুনি গাড়ীৰ হুডত কণী সিজাব পাৰিব। _END                         \n1741  its so hot that you could cook an egg on the hood of a car          START_ ইমানেই গৰম যে তুমি গাড়ীৰ হুডত কণী সিজাব পাৰিবা। _END                         \n1742  i just kept asking tom the same question but he never answered me   START_ মই টমক একেই প্ৰশ্ন সুধিয়েই থাকোঁ কিন্তু সি মোক কেতিয়াও উত্তৰ দিয়া নাই। _END\n1743  it took me more than two hours to translate a few pages of english  START_ ইংৰাজীৰ কেইখনমান পৃষ্ঠা অনুবাদ কৰোঁতে মোৰ দুঘণ্টাৰো অধিক সময় লাগিল। _END     \n1744  tom mentioned that he and mary were thinking about getting married  START_ টম্‌ আৰু মেৰীয়ে বিয়া পতাৰ কথা ভাবি আছে বুলি তেওঁ উল্লেখ কৰিলে। _END         ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>assamese_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1740</th>\n      <td>its so hot that you could cook an egg on the hood of a car</td>\n      <td>START_ ইমানেই গৰম যে আপুনি গাড়ীৰ হুডত কণী সিজাব পাৰিব। _END</td>\n    </tr>\n    <tr>\n      <th>1741</th>\n      <td>its so hot that you could cook an egg on the hood of a car</td>\n      <td>START_ ইমানেই গৰম যে তুমি গাড়ীৰ হুডত কণী সিজাব পাৰিবা। _END</td>\n    </tr>\n    <tr>\n      <th>1742</th>\n      <td>i just kept asking tom the same question but he never answered me</td>\n      <td>START_ মই টমক একেই প্ৰশ্ন সুধিয়েই থাকোঁ কিন্তু সি মোক কেতিয়াও উত্তৰ দিয়া নাই। _END</td>\n    </tr>\n    <tr>\n      <th>1743</th>\n      <td>it took me more than two hours to translate a few pages of english</td>\n      <td>START_ ইংৰাজীৰ কেইখনমান পৃষ্ঠা অনুবাদ কৰোঁতে মোৰ দুঘণ্টাৰো অধিক সময় লাগিল। _END</td>\n    </tr>\n    <tr>\n      <th>1744</th>\n      <td>tom mentioned that he and mary were thinking about getting married</td>\n      <td>START_ টম্‌ আৰু মেৰীয়ে বিয়া পতাৰ কথা ভাবি আছে বুলি তেওঁ উল্লেখ কৰিলে। _END</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Get English and Hindi Vocabulary\nall_eng_words=set()\nfor eng in lines['english_sentence']:\n    for word in eng.split():\n        if word not in all_eng_words:\n            all_eng_words.add(word)\n\nall_assamese_words=set()\nfor assm in lines['assamese_sentence']:\n    for word in assm.split():\n        if word not in all_assamese_words:\n            all_assamese_words.add(word)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(all_eng_words)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"1218"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(all_assamese_words)","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"2192"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\nlines['length_assm_sentence']=lines['assamese_sentence'].apply(lambda x:len(x.split(\" \")))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.head()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"  english_sentence     assamese_sentence  length_eng_sentence  length_assm_sentence\n0  hi               START_ নমস্কাৰ। _END  1                    3                   \n1  hi               START_ হাই। _END      1                    3                   \n2  run              START_ দৌৰ! _END      1                    3                   \n3  run              START_ দৌৰাঁ! _END    1                    3                   \n4  run              START_ দৌৰক! _END     1                    3                   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>assamese_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_assm_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hi</td>\n      <td>START_ নমস্কাৰ। _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hi</td>\n      <td>START_ হাই। _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>run</td>\n      <td>START_ দৌৰ! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>run</td>\n      <td>START_ দৌৰাঁ! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>run</td>\n      <td>START_ দৌৰক! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines[lines['length_eng_sentence']>30].shape","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"(0, 4)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines=lines[lines['length_eng_sentence']<=20]\nlines=lines[lines['length_assm_sentence']<=20]","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.shape","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"(1745, 4)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"maximum length of Assamese Sentence \",max(lines['length_assm_sentence']))\nprint(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))","execution_count":22,"outputs":[{"output_type":"stream","text":"maximum length of Assamese Sentence  16\nmaximum length of English Sentence  15\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length_src=max(lines['length_assm_sentence'])\nmax_length_tar=max(lines['length_eng_sentence'])","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_words = sorted(list(all_eng_words))\ntarget_words = sorted(list(all_assamese_words))\nnum_encoder_tokens = len(all_eng_words)\nnum_decoder_tokens = len(all_assamese_words)\nnum_encoder_tokens, num_decoder_tokens","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"(1218, 2192)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_decoder_tokens += 1 #for zero padding","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\ntarget_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\nreverse_target_char_index = dict((i, word) for word, i in target_token_index.items())","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reverse_input_char_index","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"{1: 'a',\n 2: 'aah',\n 3: 'able',\n 4: 'aboard',\n 5: 'about',\n 6: 'above',\n 7: 'abroad',\n 8: 'absent',\n 9: 'accept',\n 10: 'accepted',\n 11: 'accident',\n 12: 'accustomed',\n 13: 'act',\n 14: 'acting',\n 15: 'active',\n 16: 'add',\n 17: 'address',\n 18: 'adjust',\n 19: 'admissions',\n 20: 'admitted',\n 21: 'advice',\n 22: 'africa',\n 23: 'after',\n 24: 'afternoon',\n 25: 'again',\n 26: 'against',\n 27: 'ahead',\n 28: 'air',\n 29: 'airmail',\n 30: 'alarm',\n 31: 'alive',\n 32: 'all',\n 33: 'allergic',\n 34: 'allowed',\n 35: 'almost',\n 36: 'alone',\n 37: 'already',\n 38: 'also',\n 39: 'always',\n 40: 'am',\n 41: 'among',\n 42: 'amused',\n 43: 'an',\n 44: 'and',\n 45: 'angry',\n 46: 'answer',\n 47: 'answered',\n 48: 'any',\n 49: 'anybody',\n 50: 'anymore',\n 51: 'anyone',\n 52: 'anything',\n 53: 'apparent',\n 54: 'applauded',\n 55: 'apple',\n 56: 'apples',\n 57: 'apron',\n 58: 'are',\n 59: 'arent',\n 60: 'argue',\n 61: 'arm',\n 62: 'around',\n 63: 'arrested',\n 64: 'arrival',\n 65: 'arrive',\n 66: 'arrived',\n 67: 'arrives',\n 68: 'artist',\n 69: 'as',\n 70: 'asia',\n 71: 'asianamerican',\n 72: 'ask',\n 73: 'asked',\n 74: 'asking',\n 75: 'at',\n 76: 'ate',\n 77: 'attack',\n 78: 'attention',\n 79: 'aunt',\n 80: 'australia',\n 81: 'away',\n 82: 'awfully',\n 83: 'babysitter',\n 84: 'back',\n 85: 'background',\n 86: 'bad',\n 87: 'bag',\n 88: 'baked',\n 89: 'baking',\n 90: 'bald',\n 91: 'banished',\n 92: 'bank',\n 93: 'baseball',\n 94: 'bathroom',\n 95: 'battery',\n 96: 'battle',\n 97: 'be',\n 98: 'beautiful',\n 99: 'became',\n 100: 'become',\n 101: 'becoming',\n 102: 'bed',\n 103: 'beef',\n 104: 'been',\n 105: 'beer',\n 106: 'before',\n 107: 'begin',\n 108: 'begun',\n 109: 'behind',\n 110: 'believe',\n 111: 'bell',\n 112: 'belongs',\n 113: 'best',\n 114: 'betray',\n 115: 'better',\n 116: 'beyond',\n 117: 'bicycle',\n 118: 'bicycles',\n 119: 'big',\n 120: 'bill',\n 121: 'birthday',\n 122: 'bit',\n 123: 'black',\n 124: 'blamed',\n 125: 'blind',\n 126: 'blinds',\n 127: 'blocks',\n 128: 'blood',\n 129: 'blouse',\n 130: 'blow',\n 131: 'blue',\n 132: 'book',\n 133: 'books',\n 134: 'boots',\n 135: 'bores',\n 136: 'boston',\n 137: 'both',\n 138: 'bought',\n 139: 'bowl',\n 140: 'boy',\n 141: 'boyfriend',\n 142: 'boyfriends',\n 143: 'brave',\n 144: 'break',\n 145: 'breathe',\n 146: 'bring',\n 147: 'broke',\n 148: 'broken',\n 149: 'brother',\n 150: 'brown',\n 151: 'bucket',\n 152: 'budding',\n 153: 'building',\n 154: 'built',\n 155: 'burns',\n 156: 'bus',\n 157: 'business',\n 158: 'businessman',\n 159: 'busy',\n 160: 'but',\n 161: 'button',\n 162: 'buy',\n 163: 'by',\n 164: 'cake',\n 165: 'call',\n 166: 'called',\n 167: 'calm',\n 168: 'came',\n 169: 'can',\n 170: 'cancer',\n 171: 'candlelight',\n 172: 'cant',\n 173: 'captured',\n 174: 'car',\n 175: 'cares',\n 176: 'carpet',\n 177: 'carrots',\n 178: 'cat',\n 179: 'cautious',\n 180: 'cave',\n 181: 'caviar',\n 182: 'cds',\n 183: 'chair',\n 184: 'champagne',\n 185: 'change',\n 186: 'changed',\n 187: 'changes',\n 188: 'chartered',\n 189: 'cheap',\n 190: 'check',\n 191: 'cheeks',\n 192: 'cheese',\n 193: 'chemistry',\n 194: 'childish',\n 195: 'children',\n 196: 'chinese',\n 197: 'chocolate',\n 198: 'choice',\n 199: 'classes',\n 200: 'cleans',\n 201: 'clear',\n 202: 'clerk',\n 203: 'clinic',\n 204: 'close',\n 205: 'clothes',\n 206: 'cloud',\n 207: 'cloudy',\n 208: 'coffee',\n 209: 'coffees',\n 210: 'cold',\n 211: 'come',\n 212: 'comedies',\n 213: 'comfort',\n 214: 'comfortable',\n 215: 'coming',\n 216: 'committee',\n 217: 'common',\n 218: 'compared',\n 219: 'complicated',\n 220: 'computer',\n 221: 'congratulations',\n 222: 'consists',\n 223: 'contents',\n 224: 'contest',\n 225: 'context',\n 226: 'continent',\n 227: 'continue',\n 228: 'cook',\n 229: 'cookies',\n 230: 'cooking',\n 231: 'cooks',\n 232: 'cops',\n 233: 'correct',\n 234: 'cost',\n 235: 'cotton',\n 236: 'cough',\n 237: 'could',\n 238: 'couldnt',\n 239: 'count',\n 240: 'countries',\n 241: 'country',\n 242: 'counts',\n 243: 'crazy',\n 244: 'creationism',\n 245: 'crowd',\n 246: 'cry',\n 247: 'cup',\n 248: 'curious',\n 249: 'curry',\n 250: 'cute',\n 251: 'cycling',\n 252: 'dance',\n 253: 'danced',\n 254: 'dancing',\n 255: 'dark',\n 256: 'dating',\n 257: 'daughter',\n 258: 'daughters',\n 259: 'day',\n 260: 'days',\n 261: 'death',\n 262: 'debt',\n 263: 'debts',\n 264: 'decision',\n 265: 'declared',\n 266: 'definitely',\n 267: 'definitions',\n 268: 'depend',\n 269: 'depends',\n 270: 'description',\n 271: 'desk',\n 272: 'developed',\n 273: 'did',\n 274: 'didnt',\n 275: 'die',\n 276: 'died',\n 277: 'diet',\n 278: 'dieting',\n 279: 'difference',\n 280: 'difficult',\n 281: 'dinner',\n 282: 'disabled',\n 283: 'disco',\n 284: 'discussion',\n 285: 'disease',\n 286: 'divide',\n 287: 'do',\n 288: 'doctor',\n 289: 'does',\n 290: 'doesnt',\n 291: 'dog',\n 292: 'dogs',\n 293: 'doing',\n 294: 'dollar',\n 295: 'dollars',\n 296: 'done',\n 297: 'dont',\n 298: 'door',\n 299: 'doubts',\n 300: 'down',\n 301: 'downtown',\n 302: 'drank',\n 303: 'dreamt',\n 304: 'dressed',\n 305: 'drink',\n 306: 'drinks',\n 307: 'drive',\n 308: 'dropped',\n 309: 'dye',\n 310: 'each',\n 311: 'eager',\n 312: 'early',\n 313: 'ears',\n 314: 'easy',\n 315: 'eat',\n 316: 'eaten',\n 317: 'egg',\n 318: 'either',\n 319: 'elaborate',\n 320: 'else',\n 321: 'embraced',\n 322: 'empty',\n 323: 'end',\n 324: 'engine',\n 325: 'english',\n 326: 'enjoy',\n 327: 'enough',\n 328: 'enter',\n 329: 'entered',\n 330: 'even',\n 331: 'evening',\n 332: 'ever',\n 333: 'every',\n 334: 'everybody',\n 335: 'everyone',\n 336: 'everything',\n 337: 'evidence',\n 338: 'exactly',\n 339: 'example',\n 340: 'exercise',\n 341: 'expect',\n 342: 'experience',\n 343: 'explain',\n 344: 'explanation',\n 345: 'express',\n 346: 'eyes',\n 347: 'face',\n 348: 'facebook',\n 349: 'facts',\n 350: 'failed',\n 351: 'fall',\n 352: 'fantastic',\n 353: 'far',\n 354: 'fast',\n 355: 'faster',\n 356: 'fat',\n 357: 'father',\n 358: 'fathers',\n 359: 'fault',\n 360: 'favorite',\n 361: 'feel',\n 362: 'feeling',\n 363: 'feels',\n 364: 'fetch',\n 365: 'fever',\n 366: 'few',\n 367: 'fierce',\n 368: 'fifteen',\n 369: 'fight',\n 370: 'fighting',\n 371: 'fill',\n 372: 'filled',\n 373: 'find',\n 374: 'finish',\n 375: 'finished',\n 376: 'fire',\n 377: 'first',\n 378: 'fish',\n 379: 'fishing',\n 380: 'fit',\n 381: 'five',\n 382: 'fix',\n 383: 'flower',\n 384: 'flowers',\n 385: 'focus',\n 386: 'follow',\n 387: 'following',\n 388: 'font',\n 389: 'food',\n 390: 'fool',\n 391: 'foolish',\n 392: 'foot',\n 393: 'for',\n 394: 'forest',\n 395: 'forever',\n 396: 'forget',\n 397: 'forgive',\n 398: 'forgot',\n 399: 'fought',\n 400: 'found',\n 401: 'frank',\n 402: 'freaks',\n 403: 'free',\n 404: 'freedom',\n 405: 'french',\n 406: 'friends',\n 407: 'from',\n 408: 'front',\n 409: 'fruit',\n 410: 'furniture',\n 411: 'game',\n 412: 'gas',\n 413: 'gate',\n 414: 'gave',\n 415: 'genuine',\n 416: 'german',\n 417: 'get',\n 418: 'gets',\n 419: 'getting',\n 420: 'girl',\n 421: 'girlfriends',\n 422: 'give',\n 423: 'glad',\n 424: 'glass',\n 425: 'go',\n 426: 'god',\n 427: 'goes',\n 428: 'going',\n 429: 'gold',\n 430: 'golf',\n 431: 'gone',\n 432: 'good',\n 433: 'goodbye',\n 434: 'got',\n 435: 'grab',\n 436: 'grade',\n 437: 'gray',\n 438: 'great',\n 439: 'greenland',\n 440: 'ground',\n 441: 'grows',\n 442: 'guitar',\n 443: 'gun',\n 444: 'hacked',\n 445: 'had',\n 446: 'hair',\n 447: 'half',\n 448: 'hands',\n 449: 'happened',\n 450: 'happening',\n 451: 'happens',\n 452: 'hard',\n 453: 'hardly',\n 454: 'has',\n 455: 'hasnt',\n 456: 'hat',\n 457: 'hate',\n 458: 'have',\n 459: 'he',\n 460: 'headache',\n 461: 'healthy',\n 462: 'hear',\n 463: 'heard',\n 464: 'heart',\n 465: 'heat',\n 466: 'heater',\n 467: 'heavier',\n 468: 'heavy',\n 469: 'heels',\n 470: 'hello',\n 471: 'help',\n 472: 'helped',\n 473: 'her',\n 474: 'here',\n 475: 'hers',\n 476: 'hes',\n 477: 'hi',\n 478: 'high',\n 479: 'him',\n 480: 'himself',\n 481: 'hinted',\n 482: 'his',\n 483: 'holes',\n 484: 'holidays',\n 485: 'home',\n 486: 'homemade',\n 487: 'homesick',\n 488: 'homework',\n 489: 'honesty',\n 490: 'hood',\n 491: 'hope',\n 492: 'hopeless',\n 493: 'hospital',\n 494: 'hot',\n 495: 'hotel',\n 496: 'hours',\n 497: 'house',\n 498: 'houses',\n 499: 'how',\n 500: 'hugged',\n 501: 'hurry',\n 502: 'hurt',\n 503: 'hurts',\n 504: 'i',\n 505: 'id',\n 506: 'if',\n 507: 'ikea',\n 508: 'ill',\n 509: 'im',\n 510: 'impatient',\n 511: 'important',\n 512: 'improved',\n 513: 'improving',\n 514: 'in',\n 515: 'incredible',\n 516: 'indicates',\n 517: 'innocent',\n 518: 'instantly',\n 519: 'intention',\n 520: 'interested',\n 521: 'interesting',\n 522: 'into',\n 523: 'intriguing',\n 524: 'invent',\n 525: 'is',\n 526: 'isnt',\n 527: 'it',\n 528: 'italian',\n 529: 'its',\n 530: 'ive',\n 531: 'i’m',\n 532: 'jackson',\n 533: 'jacksons',\n 534: 'jail',\n 535: 'jam',\n 536: 'japan',\n 537: 'job',\n 538: 'john',\n 539: 'journalist',\n 540: 'journey',\n 541: 'juice',\n 542: 'jump',\n 543: 'jumped',\n 544: 'just',\n 545: 'justly',\n 546: 'keep',\n 547: 'kept',\n 548: 'key',\n 549: 'kid',\n 550: 'kidding',\n 551: 'kill',\n 552: 'kind',\n 553: 'king',\n 554: 'kingdom',\n 555: 'kissed',\n 556: 'kneeling',\n 557: 'knew',\n 558: 'know',\n 559: 'knows',\n 560: 'lady',\n 561: 'language',\n 562: 'laptop',\n 563: 'large',\n 564: 'lasagna',\n 565: 'last',\n 566: 'late',\n 567: 'laugh',\n 568: 'lawn',\n 569: 'learn',\n 570: 'learned',\n 571: 'learning',\n 572: 'leather',\n 573: 'leave',\n 574: 'left',\n 575: 'lend',\n 576: 'lent',\n 577: 'less',\n 578: 'lesson',\n 579: 'let',\n 580: 'lets',\n 581: 'letter',\n 582: 'liable',\n 583: 'lie',\n 584: 'lied',\n 585: 'life',\n 586: 'lift',\n 587: 'lights',\n 588: 'like',\n 589: 'likes',\n 590: 'list',\n 591: 'listen',\n 592: 'little',\n 593: 'live',\n 594: 'lived',\n 595: 'lives',\n 596: 'living',\n 597: 'located',\n 598: 'logic',\n 599: 'logical',\n 600: 'lonely',\n 601: 'long',\n 602: 'longer',\n 603: 'look',\n 604: 'looked',\n 605: 'looking',\n 606: 'loose',\n 607: 'lost',\n 608: 'lot',\n 609: 'louder',\n 610: 'love',\n 611: 'loved',\n 612: 'loves',\n 613: 'luck',\n 614: 'lucky',\n 615: 'luggage',\n 616: 'lunch',\n 617: 'lying',\n 618: 'machinery',\n 619: 'made',\n 620: 'make',\n 621: 'makes',\n 622: 'manages',\n 623: 'mango',\n 624: 'manners',\n 625: 'many',\n 626: 'map',\n 627: 'married',\n 628: 'mary',\n 629: 'marys',\n 630: 'matter',\n 631: 'matters',\n 632: 'may',\n 633: 'maybe',\n 634: 'me',\n 635: 'mean',\n 636: 'meat',\n 637: 'medicine',\n 638: 'meet',\n 639: 'meeting',\n 640: 'memorize',\n 641: 'men',\n 642: 'mentioned',\n 643: 'menu',\n 644: 'message',\n 645: 'microscopes',\n 646: 'might',\n 647: 'milk',\n 648: 'mince',\n 649: 'mind',\n 650: 'mine',\n 651: 'minute',\n 652: 'minutes',\n 653: 'miss',\n 654: 'mistakes',\n 655: 'mix',\n 656: 'mom',\n 657: 'money',\n 658: 'months',\n 659: 'mood',\n 660: 'more',\n 661: 'morning',\n 662: 'most',\n 663: 'mother',\n 664: 'motivated',\n 665: 'mouth',\n 666: 'move',\n 667: 'moved',\n 668: 'movie',\n 669: 'mowing',\n 670: 'mozart',\n 671: 'much',\n 672: 'muddy',\n 673: 'multiply',\n 674: 'music',\n 675: 'must',\n 676: 'mustve',\n 677: 'my',\n 678: 'name',\n 679: 'natural',\n 680: 'navy',\n 681: 'nearest',\n 682: 'nearly',\n 683: 'need',\n 684: 'needed',\n 685: 'needs',\n 686: 'neighbor',\n 687: 'never',\n 688: 'new',\n 689: 'news',\n 690: 'nice',\n 691: 'night',\n 692: 'no',\n 693: 'nobody',\n 694: 'none',\n 695: 'nose',\n 696: 'not',\n 697: 'nothing',\n 698: 'novel',\n 699: 'now',\n 700: 'number',\n 701: 'nurse',\n 702: 'obeyed',\n 703: 'object',\n 704: 'of',\n 705: 'off',\n 706: 'offer',\n 707: 'office',\n 708: 'often',\n 709: 'oh',\n 710: 'old',\n 711: 'on',\n 712: 'once',\n 713: 'one',\n 714: 'ones',\n 715: 'only',\n 716: 'open',\n 717: 'opinion',\n 718: 'or',\n 719: 'order',\n 720: 'ordered',\n 721: 'os',\n 722: 'other',\n 723: 'ought',\n 724: 'our',\n 725: 'ourselves',\n 726: 'out',\n 727: 'outside',\n 728: 'over',\n 729: 'overcast',\n 730: 'own',\n 731: 'pages',\n 732: 'pain',\n 733: 'painting',\n 734: 'pairs',\n 735: 'pale',\n 736: 'paper',\n 737: 'parking',\n 738: 'part',\n 739: 'partly',\n 740: 'password',\n 741: 'patient',\n 742: 'pay',\n 743: 'pays',\n 744: 'peanuts',\n 745: 'peeked',\n 746: 'pen',\n 747: 'pencil',\n 748: 'pens',\n 749: 'people',\n 750: 'perfect',\n 751: 'person',\n 752: 'phone',\n 753: 'phoned',\n 754: 'photographs',\n 755: 'photos',\n 756: 'pink',\n 757: 'pizza',\n 758: 'place',\n 759: 'plainly',\n 760: 'plan',\n 761: 'play',\n 762: 'played',\n 763: 'plays',\n 764: 'please',\n 765: 'pm',\n 766: 'poem',\n 767: 'poetry',\n 768: 'point',\n 769: 'police',\n 770: 'policeman',\n 771: 'politician',\n 772: 'pool',\n 773: 'popular',\n 774: 'possibility',\n 775: 'possible',\n 776: 'postpone',\n 777: 'potatoes',\n 778: 'poured',\n 779: 'precedes',\n 780: 'precise',\n 781: 'prefer',\n 782: 'prepare',\n 783: 'previous',\n 784: 'prime',\n 785: 'problem',\n 786: 'proceed',\n 787: 'programming',\n 788: 'promise',\n 789: 'promised',\n 790: 'proud',\n 791: 'pseudoscience',\n 792: 'pulled',\n 793: 'purple',\n 794: 'purpose',\n 795: 'push',\n 796: 'put',\n 797: 'question',\n 798: 'quiet',\n 799: 'quit',\n 800: 'rain',\n 801: 'rained',\n 802: 'ran',\n 803: 'rat',\n 804: 'rate',\n 805: 'rather',\n 806: 'read',\n 807: 'reading',\n 808: 'ready',\n 809: 'real',\n 810: 'really',\n 811: 'reason',\n 812: 'received',\n 813: 'reconsider',\n 814: 'records',\n 815: 'red',\n 816: 'referring',\n 817: 'registered',\n 818: 'regret',\n 819: 'reinstall',\n 820: 'rejected',\n 821: 'related',\n 822: 'relax',\n 823: 'reliable',\n 824: 'rely',\n 825: 'remained',\n 826: 'remind',\n 827: 'report',\n 828: 'requires',\n 829: 'resemble',\n 830: 'resigned',\n 831: 'respect',\n 832: 'restroom',\n 833: 'retirement',\n 834: 'return',\n 835: 'rice',\n 836: 'rich',\n 837: 'right',\n 838: 'ringing',\n 839: 'road',\n 840: 'roll',\n 841: 'rolled',\n 842: 'rome',\n 843: 'room',\n 844: 'rotten',\n 845: 'rough',\n 846: 'ruled',\n 847: 'rules',\n 848: 'run',\n 849: 'running',\n 850: 'runny',\n 851: 'runs',\n 852: 'safe',\n 853: 'said',\n 854: 'sale',\n 855: 'same',\n 856: 'sandwiches',\n 857: 'saved',\n 858: 'saw',\n 859: 'say',\n 860: 'saying',\n 861: 'scale',\n 862: 'scare',\n 863: 'scarf',\n 864: 'scenery',\n 865: 'school',\n 866: 'schools',\n 867: 'screaming',\n 868: 'seat',\n 869: 'seats',\n 870: 'secret',\n 871: 'see',\n 872: 'seeing',\n 873: 'seem',\n 874: 'seemed',\n 875: 'seems',\n 876: 'seen',\n 877: 'seldom',\n 878: 'sense',\n 879: 'sent',\n 880: 'seriously',\n 881: 'several',\n 882: 'sexy',\n 883: 'shall',\n 884: 'she',\n 885: 'shes',\n 886: 'shirt',\n 887: 'shirts',\n 888: 'shoelaces',\n 889: 'shoes',\n 890: 'shopping',\n 891: 'shortly',\n 892: 'shot',\n 893: 'should',\n 894: 'shouldnt',\n 895: 'shouldve',\n 896: 'shovel',\n 897: 'show',\n 898: 'showed',\n 899: 'sick',\n 900: 'silent',\n 901: 'silver',\n 902: 'simple',\n 903: 'since',\n 904: 'sing',\n 905: 'singer',\n 906: 'single',\n 907: 'sir',\n 908: 'sister',\n 909: 'sit',\n 910: 'situation',\n 911: 'six',\n 912: 'size',\n 913: 'sky',\n 914: 'sleep',\n 915: 'sleeping',\n 916: 'sleeve',\n 917: 'slowly',\n 918: 'small',\n 919: 'smaller',\n 920: 'smart',\n 921: 'smarter',\n 922: 'smell',\n 923: 'smells',\n 924: 'smoke',\n 925: 'smokes',\n 926: 'smoking',\n 927: 'sneeze',\n 928: 'snow',\n 929: 'snowing',\n 930: 'so',\n 931: 'socks',\n 932: 'sold',\n 933: 'some',\n 934: 'somebody',\n 935: 'someone',\n 936: 'something',\n 937: 'sometimes',\n 938: 'son',\n 939: 'soon',\n 940: 'sooner',\n 941: 'sorry',\n 942: 'sounds',\n 943: 'speak',\n 944: 'speaks',\n 945: 'speechless',\n 946: 'spent',\n 947: 'spoke',\n 948: 'sports',\n 949: 'stand',\n 950: 'standard',\n 951: 'start',\n 952: 'started',\n 953: 'statement',\n 954: 'station',\n 955: 'stay',\n 956: 'step',\n 957: 'stick',\n 958: 'still',\n 959: 'stomach',\n 960: 'stop',\n 961: 'stopped',\n 962: 'store',\n 963: 'storm',\n 964: 'story',\n 965: 'straight',\n 966: 'strange',\n 967: 'streets',\n 968: 'strong',\n 969: 'student',\n 970: 'students',\n 971: 'study',\n 972: 'studying',\n 973: 'stuff',\n 974: 'submitted',\n 975: 'subway',\n 976: 'such',\n 977: 'suddenly',\n 978: 'sugar',\n 979: 'suggest',\n 980: 'suit',\n 981: 'suitable',\n 982: 'summer',\n 983: 'sunday',\n 984: 'sunshine',\n 985: 'supermarket',\n 986: 'support',\n 987: 'surely',\n 988: 'swear',\n 989: 'sweater',\n 990: 'sweet',\n 991: 'swim',\n 992: 'swims',\n 993: 'symptoms',\n 994: 'table',\n 995: 'tablet',\n 996: 'takasu',\n 997: 'take',\n 998: 'taken',\n 999: 'takes',\n 1000: 'taking',\n ...}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.head(10)","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"  english_sentence        assamese_sentence  length_eng_sentence  length_assm_sentence\n0  hi               START_ নমস্কাৰ। _END     1                    3                   \n1  hi               START_ হাই। _END         1                    3                   \n2  run              START_ দৌৰ! _END         1                    3                   \n3  run              START_ দৌৰাঁ! _END       1                    3                   \n4  run              START_ দৌৰক! _END        1                    3                   \n5  who              START_ কোন? _END         1                    3                   \n6  wow              START_ বাঃ! _END         1                    3                   \n7  fire             START_ জুই! _END         1                    3                   \n8  help             START_ সহায় কৰাঁ! _END  1                    4                   \n9  help             START_ সহায় কৰক! _END   1                    4                   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>assamese_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_assm_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hi</td>\n      <td>START_ নমস্কাৰ। _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hi</td>\n      <td>START_ হাই। _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>run</td>\n      <td>START_ দৌৰ! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>run</td>\n      <td>START_ দৌৰাঁ! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>run</td>\n      <td>START_ দৌৰক! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>who</td>\n      <td>START_ কোন? _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>wow</td>\n      <td>START_ বাঃ! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>fire</td>\n      <td>START_ জুই! _END</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>help</td>\n      <td>START_ সহায় কৰাঁ! _END</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>help</td>\n      <td>START_ সহায় কৰক! _END</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines = shuffle(lines)\nlines.head(10)","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"                                  english_sentence                                        assamese_sentence  length_eng_sentence  length_assm_sentence\n1388  it was great to see you again                 START_ আপোনাক আকৌ লগ পাই বৰ ভাল লাগিল। _END              7                    9                   \n986   my father gave me a game                      START_ মোৰ দেউতাই মোক এটা গেম দিলে। _END                 6                    8                   \n1644  thats the reason i accepted the offer         START_ সেই কাৰণেই মই অফাৰটো গ্ৰহণ কৰিলোঁ। _END           7                    8                   \n250   you are hopeless                              START_ আপুনি অলায়ক। _END                                3                    4                   \n558   i count on your help                          START_ মই তোমাৰ সহায়ৰ ওপৰত নিৰ্ভৰশীল। _END              5                    7                   \n392   was the movie good                            START_ কথাছবিখন ভাল আছিলনে? _END                         4                    5                   \n225   please elaborate                              START_ বহলাই কোৱাচোন। _END                               2                    4                   \n1671  i really dont want to live in australia       START_ মই সঁচাকৈয়ে অষ্ট্ৰেলিয়াত থাকিব নিবিচাৰোঁ। _END  8                    7                   \n1516  please take off your muddy boots              START_ আপোনাৰ বোকা লাগি থকা বুটযোৰ খুলি থওকচোন। _END     6                    9                   \n1702  the scenery was beautiful beyond description  START_ বৰ্ণনা কৰিব নোৱাৰা সুন্দৰ দৃশ্য আছিল। _END        6                    8                   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>assamese_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_assm_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1388</th>\n      <td>it was great to see you again</td>\n      <td>START_ আপোনাক আকৌ লগ পাই বৰ ভাল লাগিল। _END</td>\n      <td>7</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>986</th>\n      <td>my father gave me a game</td>\n      <td>START_ মোৰ দেউতাই মোক এটা গেম দিলে। _END</td>\n      <td>6</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1644</th>\n      <td>thats the reason i accepted the offer</td>\n      <td>START_ সেই কাৰণেই মই অফাৰটো গ্ৰহণ কৰিলোঁ। _END</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>you are hopeless</td>\n      <td>START_ আপুনি অলায়ক। _END</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>558</th>\n      <td>i count on your help</td>\n      <td>START_ মই তোমাৰ সহায়ৰ ওপৰত নিৰ্ভৰশীল। _END</td>\n      <td>5</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>was the movie good</td>\n      <td>START_ কথাছবিখন ভাল আছিলনে? _END</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>225</th>\n      <td>please elaborate</td>\n      <td>START_ বহলাই কোৱাচোন। _END</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1671</th>\n      <td>i really dont want to live in australia</td>\n      <td>START_ মই সঁচাকৈয়ে অষ্ট্ৰেলিয়াত থাকিব নিবিচাৰোঁ। _END</td>\n      <td>8</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1516</th>\n      <td>please take off your muddy boots</td>\n      <td>START_ আপোনাৰ বোকা লাগি থকা বুটযোৰ খুলি থওকচোন। _END</td>\n      <td>6</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1702</th>\n      <td>the scenery was beautiful beyond description</td>\n      <td>START_ বৰ্ণনা কৰিব নোৱাৰা সুন্দৰ দৃশ্য আছিল। _END</td>\n      <td>6</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Split the data into train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = lines['english_sentence'], lines['assamese_sentence']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\nX_train.shape, X_test.shape","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"((1396,), (349,))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Let us save this data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.to_pickle('X_train.pkl')\nX_test.to_pickle('X_test.pkl')\n","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_batch(X = X_train, y = y_train, batch_size = 128):\n    ''' Generate a batch of data '''\n    while True:\n        for j in range(0, len(X), batch_size):\n            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n                for t, word in enumerate(input_text.split()):\n                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n                for t, word in enumerate(target_text.split()):\n                    if t<len(target_text.split())-1:\n                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n                    if t>0:\n                        # decoder target sequence (one hot encoded)\n                        # does not include the START_ token\n                        # Offset by one timestep\n                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n            yield([encoder_input_data, decoder_input_data], decoder_target_data)","execution_count":33,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoder-Decoder Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_dim=300","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoder\nencoder_inputs = Input(shape=(None,))\nenc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]","execution_count":35,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\ndec_emb = dec_emb_layer(decoder_inputs)\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don't use the\n# return states in the training model, but we will use them in inference.\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb,\n                                     initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy')","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":38,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, None, 300)    365400      input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, None, 300)    657900      input_2[0][0]                    \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, 300), (None, 721200      embedding_1[0][0]                \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   [(None, None, 300),  721200      embedding_2[0][0]                \n                                                                 lstm_1[0][1]                     \n                                                                 lstm_1[0][2]                     \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, None, 2193)   660093      lstm_2[0][0]                     \n==================================================================================================\nTotal params: 3,125,793\nTrainable params: 3,125,793\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_samples = len(X_train)\nval_samples = len(X_test)\nbatch_size = 128\nepochs = 100","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n                    steps_per_epoch = train_samples//batch_size,\n                    epochs=epochs,\n                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n                    validation_steps = val_samples//batch_size)\n\n","execution_count":40,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nEpoch 1/100\n10/10 [==============================] - 5s 479ms/step - loss: 6.8822 - val_loss: 6.1382\nEpoch 2/100\n10/10 [==============================] - 1s 70ms/step - loss: 5.8079 - val_loss: 5.9710\nEpoch 3/100\n10/10 [==============================] - 1s 67ms/step - loss: 5.5580 - val_loss: 5.8350\nEpoch 4/100\n10/10 [==============================] - 1s 60ms/step - loss: 5.4072 - val_loss: 5.7364\nEpoch 5/100\n10/10 [==============================] - 1s 60ms/step - loss: 5.2769 - val_loss: 5.8005\nEpoch 6/100\n10/10 [==============================] - 1s 60ms/step - loss: 5.1544 - val_loss: 5.6554\nEpoch 7/100\n10/10 [==============================] - 1s 61ms/step - loss: 5.0400 - val_loss: 5.6666\nEpoch 8/100\n10/10 [==============================] - 1s 61ms/step - loss: 4.9290 - val_loss: 5.7121\nEpoch 9/100\n10/10 [==============================] - 1s 61ms/step - loss: 4.7094 - val_loss: 5.5629\nEpoch 11/100\n10/10 [==============================] - 1s 61ms/step - loss: 4.5874 - val_loss: 5.7421\nEpoch 12/100\n10/10 [==============================] - 1s 74ms/step - loss: 4.4994 - val_loss: 5.5438\nEpoch 13/100\n10/10 [==============================] - 1s 71ms/step - loss: 4.3849 - val_loss: 5.5056\nEpoch 14/100\n10/10 [==============================] - 1s 60ms/step - loss: 4.2481 - val_loss: 5.7203\nEpoch 15/100\n10/10 [==============================] - 1s 67ms/step - loss: 4.1397 - val_loss: 5.5109\nEpoch 16/100\n10/10 [==============================] - 1s 61ms/step - loss: 4.0182 - val_loss: 5.4437\nEpoch 17/100\n10/10 [==============================] - 1s 58ms/step - loss: 3.9028 - val_loss: 5.6245\nEpoch 18/100\n10/10 [==============================] - 1s 60ms/step - loss: 3.7744 - val_loss: 5.4654\nEpoch 19/100\n10/10 [==============================] - 1s 59ms/step - loss: 3.6552 - val_loss: 5.4095\nEpoch 20/100\n10/10 [==============================] - 1s 58ms/step - loss: 3.5655 - val_loss: 5.5797\nEpoch 21/100\n10/10 [==============================] - 1s 59ms/step - loss: 3.4354 - val_loss: 5.4329\nEpoch 22/100\n10/10 [==============================] - 1s 58ms/step - loss: 3.3246 - val_loss: 5.3779\nEpoch 23/100\n10/10 [==============================] - 1s 59ms/step - loss: 3.2343 - val_loss: 5.5337\nEpoch 24/100\n10/10 [==============================] - 1s 60ms/step - loss: 3.1327 - val_loss: 5.3852\nEpoch 25/100\n10/10 [==============================] - 1s 58ms/step - loss: 3.0293 - val_loss: 5.3394\nEpoch 26/100\n10/10 [==============================] - 1s 57ms/step - loss: 2.9292 - val_loss: 5.5153\nEpoch 27/100\n10/10 [==============================] - 1s 59ms/step - loss: 2.8469 - val_loss: 5.3960\nEpoch 28/100\n10/10 [==============================] - 1s 60ms/step - loss: 2.7436 - val_loss: 5.3089\nEpoch 29/100\n10/10 [==============================] - 1s 59ms/step - loss: 2.6620 - val_loss: 5.4620\nEpoch 30/100\n10/10 [==============================] - 1s 77ms/step - loss: 2.5626 - val_loss: 5.3735\nEpoch 31/100\n10/10 [==============================] - 1s 67ms/step - loss: 2.4949 - val_loss: 5.2881\nEpoch 32/100\n10/10 [==============================] - 1s 60ms/step - loss: 2.3894 - val_loss: 5.4464\nEpoch 33/100\n10/10 [==============================] - 1s 60ms/step - loss: 2.3122 - val_loss: 5.3422\nEpoch 34/100\n10/10 [==============================] - 1s 57ms/step - loss: 2.2588 - val_loss: 5.2658\nEpoch 35/100\n10/10 [==============================] - 1s 80ms/step - loss: 2.1651 - val_loss: 5.3897\nEpoch 36/100\n10/10 [==============================] - 1s 87ms/step - loss: 2.0854 - val_loss: 5.3148\nEpoch 37/100\n10/10 [==============================] - 1s 62ms/step - loss: 2.0224 - val_loss: 5.2147\nEpoch 38/100\n10/10 [==============================] - 1s 62ms/step - loss: 1.9431 - val_loss: 5.3777\nEpoch 39/100\n10/10 [==============================] - 1s 61ms/step - loss: 1.8774 - val_loss: 5.3076\nEpoch 40/100\n10/10 [==============================] - 1s 58ms/step - loss: 1.7950 - val_loss: 5.1935\nEpoch 41/100\n10/10 [==============================] - 1s 60ms/step - loss: 1.7348 - val_loss: 5.3588\nEpoch 42/100\n10/10 [==============================] - 1s 62ms/step - loss: 1.6696 - val_loss: 5.3224\nEpoch 43/100\n10/10 [==============================] - 1s 60ms/step - loss: 1.6100 - val_loss: 5.1613\nEpoch 44/100\n10/10 [==============================] - 1s 57ms/step - loss: 1.5356 - val_loss: 5.3416\nEpoch 45/100\n10/10 [==============================] - 1s 58ms/step - loss: 1.4804 - val_loss: 5.2749\nEpoch 46/100\n10/10 [==============================] - 1s 61ms/step - loss: 1.4268 - val_loss: 5.1460\nEpoch 47/100\n10/10 [==============================] - 1s 71ms/step - loss: 1.3741 - val_loss: 5.3065\nEpoch 48/100\n10/10 [==============================] - 1s 74ms/step - loss: 1.3106 - val_loss: 5.2660\nEpoch 49/100\n10/10 [==============================] - 1s 66ms/step - loss: 1.2545 - val_loss: 5.1041\nEpoch 50/100\n10/10 [==============================] - 1s 62ms/step - loss: 1.2072 - val_loss: 5.2922\nEpoch 51/100\n10/10 [==============================] - 1s 62ms/step - loss: 1.1433 - val_loss: 5.2777\nEpoch 52/100\n10/10 [==============================] - 1s 61ms/step - loss: 1.1127 - val_loss: 5.1106\nEpoch 53/100\n10/10 [==============================] - 1s 60ms/step - loss: 1.0595 - val_loss: 5.2989\nEpoch 54/100\n10/10 [==============================] - 1s 62ms/step - loss: 1.0117 - val_loss: 5.2460\nEpoch 55/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.9490 - val_loss: 5.0974\nEpoch 56/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.9313 - val_loss: 5.2673\nEpoch 57/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.8828 - val_loss: 5.2359\nEpoch 58/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.8486 - val_loss: 5.0843\nEpoch 59/100\n10/10 [==============================] - 1s 58ms/step - loss: 0.8077 - val_loss: 5.2499\nEpoch 60/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.7621 - val_loss: 5.2485\nEpoch 61/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.7378 - val_loss: 5.0689\nEpoch 62/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.6925 - val_loss: 5.2520\nEpoch 63/100\n10/10 [==============================] - 1s 61ms/step - loss: 0.6649 - val_loss: 5.2801\nEpoch 64/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.6438 - val_loss: 5.0907\nEpoch 65/100\n10/10 [==============================] - 1s 84ms/step - loss: 0.6101 - val_loss: 5.2429\nEpoch 66/100\n10/10 [==============================] - 1s 65ms/step - loss: 0.5647 - val_loss: 5.2384\nEpoch 67/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.5565 - val_loss: 5.0643\nEpoch 68/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.5319 - val_loss: 5.2329\nEpoch 69/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.4975 - val_loss: 5.2530\nEpoch 70/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.4757 - val_loss: 5.0767\nEpoch 71/100\n10/10 [==============================] - 1s 63ms/step - loss: 0.4621 - val_loss: 5.2396\nEpoch 72/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.4357 - val_loss: 5.2796\nEpoch 73/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.4148 - val_loss: 5.1018\nEpoch 74/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.4029 - val_loss: 5.2608\nEpoch 75/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.3806 - val_loss: 5.2869\nEpoch 76/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.3616 - val_loss: 5.0931\nEpoch 77/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.3402 - val_loss: 5.2869\n","name":"stdout"},{"output_type":"stream","text":"Epoch 78/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.3363 - val_loss: 5.2668\nEpoch 79/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.3233 - val_loss: 5.1108\nEpoch 80/100\n10/10 [==============================] - 1s 58ms/step - loss: 0.3058 - val_loss: 5.2964\nEpoch 81/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.2931 - val_loss: 5.3059\nEpoch 82/100\n10/10 [==============================] - 1s 58ms/step - loss: 0.2791 - val_loss: 5.1312\nEpoch 83/100\n10/10 [==============================] - 1s 81ms/step - loss: 0.2765 - val_loss: 5.3377\nEpoch 84/100\n10/10 [==============================] - 1s 63ms/step - loss: 0.2609 - val_loss: 5.3840\nEpoch 85/100\n10/10 [==============================] - 1s 58ms/step - loss: 0.2534 - val_loss: 5.1711\nEpoch 86/100\n10/10 [==============================] - 1s 97ms/step - loss: 0.2385 - val_loss: 5.3549\nEpoch 87/100\n10/10 [==============================] - 1s 65ms/step - loss: 0.2336 - val_loss: 5.3730\nEpoch 88/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.2268 - val_loss: 5.1792\nEpoch 89/100\n10/10 [==============================] - 1s 58ms/step - loss: 0.2175 - val_loss: 5.3573\nEpoch 90/100\n10/10 [==============================] - 1s 58ms/step - loss: 0.2094 - val_loss: 5.3884\nEpoch 91/100\n10/10 [==============================] - 1s 58ms/step - loss: 0.2052 - val_loss: 5.2325\nEpoch 92/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.1991 - val_loss: 5.4167\nEpoch 93/100\n10/10 [==============================] - 1s 58ms/step - loss: 0.1915 - val_loss: 5.5001\nEpoch 94/100\n10/10 [==============================] - 1s 61ms/step - loss: 0.1870 - val_loss: 5.3119\nEpoch 95/100\n10/10 [==============================] - 1s 62ms/step - loss: 0.1807 - val_loss: 5.4489\nEpoch 96/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.1760 - val_loss: 5.4498\nEpoch 97/100\n10/10 [==============================] - 1s 59ms/step - loss: 0.1684 - val_loss: 5.2960\nEpoch 98/100\n10/10 [==============================] - 1s 57ms/step - loss: 0.1667 - val_loss: 5.4661\nEpoch 99/100\n10/10 [==============================] - 1s 60ms/step - loss: 0.1632 - val_loss: 5.4541\nEpoch 100/100\n10/10 [==============================] - 1s 71ms/step - loss: 0.1625 - val_loss: 5.2963\n","name":"stdout"},{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"<keras.callbacks.History at 0x7f25674e1d68>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.save_weights('nmt_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode the input sequence to get the \"thought vectors\"\nencoder_model = Model(encoder_inputs, encoder_states)\n\n# Decoder setup\n# Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\ndec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n\n# To predict the next word in the sequence, set the initial states to the states from the previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2)\n","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0] = target_token_index['START_']\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += ' '+sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        if (sampled_char == '_END' or\n           len(decoded_sentence) > 50):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = generate_batch(X_train, y_train, batch_size = 1)\nfor k in range(-1,20):\n    k+=1\n    (input_seq, actual_output), _ = next(train_gen)\n    decoded_sentence = decode_sequence(input_seq)\n    print('Input English sentence:', X_train[k:k+1].values[0])\n    print('Actual Assamese Translation:', y_train[k:k+1].values[0][6:-4])\n    print('Predicted Assamese Translation:', decoded_sentence[:-4])\n    print('*************************\\n')","execution_count":46,"outputs":[{"output_type":"stream","text":"Input English sentence: ive been arrested several times\nActual Assamese Translation:  মোক কেইবাবাৰো গ্ৰেপ্তাৰ কৰা হৈছে। \nPredicted Assamese Translation:  মোক কেইবাবাৰো গ্ৰেপ্তাৰ কৰা হৈছে। \n*************************\n\nInput English sentence: he blamed me for not coming\nActual Assamese Translation:  তেওঁ নহাৰ বাবে মোক দোষ দিছে। \nPredicted Assamese Translation:  তেওঁ নহাৰ বাবে মোক দোষ দিছে। \n*************************\n\nInput English sentence: it doesnt snow here very often\nActual Assamese Translation:  ইয়াত ইমান সঘনাই তুষাৰপাত নহয়। \nPredicted Assamese Translation:  ইয়াত ইমান ঘনাই বৰফ নপৰে। \n*************************\n\nInput English sentence: how are you\nActual Assamese Translation:  তুমি কেনে আছা? \nPredicted Assamese Translation:  আপুনি কেনে আছে? \n*************************\n\nInput English sentence: no one doubts that tom will do that tomorrow\nActual Assamese Translation:  নিঃসন্দেহে টমে সেয়া কাইলৈ কৰিব। \nPredicted Assamese Translation:  নিঃসন্দেহে টমে সেয়া কাইলৈ কৰিব। \n*************************\n\nInput English sentence: my mother cant come\nActual Assamese Translation:  মোৰ মা আহিব নোৱাৰে। \nPredicted Assamese Translation:  মোৰ মা আহিব নোৱাৰে। \n*************************\n\nInput English sentence: this is my brother\nActual Assamese Translation:  এইজন মোৰ ভাতৃ। \nPredicted Assamese Translation:  এইজন মোৰ ককাই। \n*************************\n\nInput English sentence: this watch is broken\nActual Assamese Translation:  এই ঘড়ীটো বেয়া। \nPredicted Assamese Translation:  এই ঘড়ীটো ভঙা। \n*************************\n\nInput English sentence: i dont think that we should rely on tom too much\nActual Assamese Translation:  আমি টমৰ ওপৰত ইমান ভৰসা কৰিব লাগে বুলি মই নাভাবোঁ। \nPredicted Assamese Translation:  আমি টমৰ ওপৰত ইমান ভৰসা কৰিব লাগে বুলি মই নাভাবোঁ। \n*************************\n\nInput English sentence: can you speak french\nActual Assamese Translation:  আপুনি ফৰাচী ক'ব পাৰেনে? \nPredicted Assamese Translation:  আপুনি ফৰাচী ক'ব পাৰেনে? \n*************************\n\nInput English sentence: step on the scale\nActual Assamese Translation:  মাপনীত উঠক। \nPredicted Assamese Translation:  মাপনীত উঠক। \n*************************\n\nInput English sentence: seeing me they suddenly stopped talking\nActual Assamese Translation:  মোক দেখি সিহঁতে হঠাৎ কথা পতা বন্ধ কৰি দিলে। \nPredicted Assamese Translation:  মোক দেখি তেওঁলোকে হঠাৎ কথা পতা বন্ধ কৰিলে। \n*************************\n\nInput English sentence: please sing\nActual Assamese Translation:  গোৱাচোন। \nPredicted Assamese Translation:  গোৱাচোন। \n*************************\n\nInput English sentence: its not a suitable topic for discussion\nActual Assamese Translation:  আলোচনাৰ বাবে এয়া উপযুক্ত বিষয় নহয়। \nPredicted Assamese Translation:  আলোচনাৰ বাবে এয়া উপযুক্ত বিষয় নহয়। \n*************************\n\nInput English sentence: toms wife is three years younger than he is\nActual Assamese Translation:  টমৰ ঘৈণীয়েক তাতকৈ তিনি বছৰ সৰু। \nPredicted Assamese Translation:  টমৰ ঘৈণীয়েক তাতকৈ তিনি বছৰ সৰু। \n*************************\n\nInput English sentence: push the button please\nActual Assamese Translation:  বুটামটো হেঁচি দিয়কচোন। \nPredicted Assamese Translation:  বুটামটো হেঁচি দিয়কচোন। \n*************************\n\nInput English sentence: we have an office located in downtown boston\nActual Assamese Translation:  ব'ষ্টনৰ ডাউনটাউনত আমাৰ এখন কাৰ্যালয় আছে। \nPredicted Assamese Translation:  ব'ষ্টনৰ ডাউনটাউনত আমাৰ এখন কাৰ্যালয় আছে। \n*************************\n\nInput English sentence: when did you arrive\nActual Assamese Translation:  তুমি কেতিয়া আহি পালা? \nPredicted Assamese Translation:  আপুনি কেতিয়া আহি পাইছে? \n*************************\n\nInput English sentence: they asked after my father\nActual Assamese Translation:  তেওঁলোকে মোৰ দেউতাৰ বিষয়ে সুধিছে। \nPredicted Assamese Translation:  সিহঁতে মোৰ দেউতাৰ কথা সুধিছে। \n*************************\n\nInput English sentence: he was more than a king\nActual Assamese Translation:  তেওঁ ৰজাতকৈও অধিক আছিল। \nPredicted Assamese Translation:  তেওঁ ৰজাতকৈও অধিক আছিল। \n*************************\n\nInput English sentence: your hair is too long\nActual Assamese Translation:  তোমাৰ চুলি বৰ বেছি দীঘল। \nPredicted Assamese Translation:  আপোনাৰ চুলি খুবেই দীঘল। \n*************************\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen = generate_batch(X_test, y_test, batch_size = 1)\nfor k in range(-1,20):\n    k+=1\n    (input_seq, actual_output), _ = next(test_gen)\n    decoded_sentence = decode_sequence(input_seq)\n    print('Input English sentence:', X_test[k:k+1].values[0])\n    print('Actual Assamese Translation:', y_test[k:k+1].values[0][6:-4])\n    print('Predicted Assamese Translation:', decoded_sentence[:-4])\n    print('*************************\\n')","execution_count":55,"outputs":[{"output_type":"stream","text":"Input English sentence: we had a lot of snow last year\nActual Assamese Translation:  যোৱাবছৰ খুব বৰফ পৰিছিল। \nPredicted Assamese Translation:  যোৱাবছৰ খুব তুষাৰপাত হৈছিল। \n*************************\n\nInput English sentence: buy some milk on your way home\nActual Assamese Translation:  ঘৰলৈ আহোঁতে অলপ গাখীৰ কিনি আনিবা। \nPredicted Assamese Translation:  ঘৰলৈ আহোঁতে অলপ গাখীৰ কিনি আনিব। \n*************************\n\nInput English sentence: my father was busy\nActual Assamese Translation:  মোৰ দেউতা ব্যস্ত আছিল। \nPredicted Assamese Translation:  মোৰ দেউতা ব্যস্ত। \n*************************\n\nInput English sentence: what is your name\nActual Assamese Translation:  তোমাৰ নামটো কি? \nPredicted Assamese Translation:  আপোনাৰ নাম কি? \n*************************\n\nInput English sentence: it seems interesting to me\nActual Assamese Translation:  মোৰ আমোদজনক যেন লাগিছে। \nPredicted Assamese Translation:  তুমি বৰ খোজানে? \n*************************\n\nInput English sentence: i made my son a new suit\nActual Assamese Translation:  মই মোৰ পুতক এযোৰ নতুন ছুট চিলাই দিছোঁ। \nPredicted Assamese Translation:  মই মোৰ ল'ৰাক এখন নতুন ঘৰ সাজি দিছোঁ। \n*************************\n\nInput English sentence: who\nActual Assamese Translation:  কোন? \nPredicted Assamese Translation:  হাই। \n*************************\n\nInput English sentence: i forget your phone number\nActual Assamese Translation:  মই তোমাৰ ফোন নম্বৰ পাহৰি যাওঁ। \nPredicted Assamese Translation:  মই তোমাৰ ফোন নম্বৰ পাহৰি যাওঁ। \n*************************\n\nInput English sentence: come and sit by me\nActual Assamese Translation:  আহি মোৰ কাষত বহক। \nPredicted Assamese Translation:  আহি মোৰ কাষত বহাঁ। \n*************************\n\nInput English sentence: this is my brother\nActual Assamese Translation:  এয়া মোৰ ভাইটি। \nPredicted Assamese Translation:  এইজন মোৰ ককাই। \n*************************\n\nInput English sentence: welcome to our home\nActual Assamese Translation:  আমাৰ ঘৰলৈ স্বাগতম। \nPredicted Assamese Translation:  তুমি এতিয়া ঘৰলৈ কৰাই নোৱাৰে। \n*************************\n\nInput English sentence: hello\nActual Assamese Translation:  হেৰা! \nPredicted Assamese Translation:  নমস্কাৰ! \n*************************\n\nInput English sentence: why are you in bed\nActual Assamese Translation:  আপুনি বিছনাত কিয়? \nPredicted Assamese Translation:  আপুনি গৈ আছে। \n*************************\n\nInput English sentence: we ordered pink but we received blue\nActual Assamese Translation:  আমি গুলপীয়া অৰ্ডাৰ দিছিলোঁ কিন্তু নীলা পালোঁ। \nPredicted Assamese Translation:  আমি আমাৰ এখন নীলা বিচৰা নাছিল। \n*************************\n\nInput English sentence: i built my son a new house\nActual Assamese Translation:  মই মোৰ পুতক এখন নতুন ঘৰ সাজি দিছোঁ। \nPredicted Assamese Translation:  মই মোৰ ল'ৰাক এখন নতুন ঘৰ সাজি দিছোঁ। \n*************************\n\nInput English sentence: poetry doesnt need to be logical\nActual Assamese Translation:  কবিতা যুক্তিসংগত হ'ব নালাগে। \nPredicted Assamese Translation:  ডাক্তৰে কিবা নতুন নাপায়। \n*************************\n\nInput English sentence: perfect\nActual Assamese Translation:  বঢ়িয়া! \nPredicted Assamese Translation:  উত্তম! \n*************************\n\nInput English sentence: my mother made me a bag\nActual Assamese Translation:  মোৰ মায়ে মোক এটা বেগ চিলাই দিছে। \nPredicted Assamese Translation:  মোৰ মায়ে কোঠালীটো চাফা কৰে। \n*************************\n\nInput English sentence: have you finished it\nActual Assamese Translation:  আপোনাৰ কৰা হ'লনে? \nPredicted Assamese Translation:  আপুনি শেষ কৰিলেনে? \n*************************\n\nInput English sentence: i cant lie to you\nActual Assamese Translation:  মই তোমাক মিছা কথা ক'ব নোৱাৰোঁ। \nPredicted Assamese Translation:  মই ত্যাগ কৰিব বিচাৰোঁ। \n*************************\n\nInput English sentence: this is genuine leather\nActual Assamese Translation:  এয়া আচল চামৰা। \nPredicted Assamese Translation:  এই ডেস্কখন ভঙা। \n*************************\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}